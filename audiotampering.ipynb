import os
import numpy as np
import librosa
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input
from tensorflow.keras.layers import LeakyReLU, GaussianNoise
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier

X=np.load("features.npy")
y=np.load("labels.npy")
print(X)
print(y)
def build_enhanced_model(input_shape):
    model = Sequential()
    
    model.add(Input(shape=(input_shape,)))
    model.add(GaussianNoise(0.1))
    
    model.add(Dense(256, kernel_regularizer=l2(0.0005)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))
    
    model.add(Dense(128, kernel_regularizer=l2(0.0005)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.4))
    
    model.add(Dense(64, kernel_regularizer=l2(0.0005)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.5))
    
    model.add(Dense(32, kernel_regularizer=l2(0.0005)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.5))
    
    model.add(Dense(1, activation='sigmoid'))
    
    optimizer = Adam(learning_rate=0.001)
    
    model.compile(optimizer=optimizer,
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    
    return model

# Train the model
def train_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=100):
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    
    history = model.fit(
        X_train, y_train,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(X_val, y_val),
        callbacks=[reduce_lr, early_stopping],
        verbose=1
    )
    
    return history

# Prepare and train the model
def prepare_and_train_model(X, y):
    # Split data into training, validation, and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    # Standardizing features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)

    input_shape = X_train_scaled.shape[1]
    model = build_enhanced_model(input_shape)
    history = train_model(model, X_train_scaled, y_train, X_val_scaled, y_val)

    # Predict on test set
    y_pred = model.predict(X_test_scaled)
    y_pred_classes = (y_pred > 0.5).astype(int)
    accuracy = accuracy_score(y_test, y_pred_classes)
    print(f"Test Accuracy: {accuracy * 100:.2f}%")
    
    # Print classification report
    print("Classification Report:\n", classification_report(y_test, y_pred_classes))

    return model, history, accuracy

# Cross-validation function
def cross_validate_model(X, y):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    model = KerasClassifier(build_fn=build_enhanced_model, input_shape=X_scaled.shape[1], epochs=100, batch_size=32)
    
    # Cross-validation scores
    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    results = cross_val_score(model, X_scaled, y, cv=kfold)
    print(f'Cross-validation mean accuracy: {results.mean() * 100:.2f}%')

# Main execution


print(f'Extracted features shape: {X.shape}')
print(f'Labels shape: {y.shape}')

# Train the model and evaluate on the test set
model, history, accuracy = prepare_and_train_model(X, y)

# Print final results
print(f"Final Test Accuracy: {accuracy * 100:.2f}%")
